{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Models Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c537721dbcd6babd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "from src.data.make_dataset import TextDataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from src.models.model_class import GediAdapter\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.394078Z",
     "start_time": "2023-11-04T20:11:41.333782Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Importing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pickle.load(open('../data/interim/text_dataset.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.542041Z",
     "start_time": "2023-11-04T20:11:42.394567Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                toxic  \\\n5   I'm not gonna have a child... ...with the same...   \n6   They're all laughing at us, so we'll kick your...   \n7     Maine was very short on black people back then.   \n11  So now their spirits are cursed, walking back ...   \n13               Come on, Cal, leave that shit alone.   \n\n                                               normal  toxic_reduction  \n5   I'm not going to breed kids with a genetic dis...         0.915109  \n6             they're laughing at us. We'll show you.         0.999361  \n7              there wasn't much black in Maine then.         0.814971  \n11  their souls are cursed, they guard the paths, ...         0.698517  \n13                         come on, Cal, put it down.         0.999357  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>normal</th>\n      <th>toxic_reduction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>I'm not gonna have a child... ...with the same...</td>\n      <td>I'm not going to breed kids with a genetic dis...</td>\n      <td>0.915109</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>They're all laughing at us, so we'll kick your...</td>\n      <td>they're laughing at us. We'll show you.</td>\n      <td>0.999361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Maine was very short on black people back then.</td>\n      <td>there wasn't much black in Maine then.</td>\n      <td>0.814971</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>So now their spirits are cursed, walking back ...</td>\n      <td>their souls are cursed, they guard the paths, ...</td>\n      <td>0.698517</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Come on, Cal, leave that shit alone.</td>\n      <td>come on, Cal, put it down.</td>\n      <td>0.999357</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.558911Z",
     "start_time": "2023-11-04T20:11:42.546505Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Splitting Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = df.split(0.7, 0.1, 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.662392Z",
     "start_time": "2023-11-04T20:11:42.558410Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "((404444, 3), (57778, 3), (115555, 3))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape, val_dataset.data.shape, test_dataset.data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.667342Z",
     "start_time": "2023-11-04T20:11:42.663017Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Trying GPT-2 based model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizer_name = \"s-nlp/t5-paraphrase-paws-msrp-opinosis-paranmt\"\n",
    "model_name = tokenizer_name\n",
    "dis_name = 's-nlp/gpt2-base-gedi-detoxification'\n",
    "\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:42.669875Z",
     "start_time": "2023-11-04T20:11:42.666465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "NEW_POS = tokenizer.encode('normal', add_special_tokens=False)[0]\n",
    "NEW_NEG = tokenizer.encode('toxic', add_special_tokens=False)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:43.138331Z",
     "start_time": "2023-11-04T20:11:42.671316Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(32100, 768)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:44.831564Z",
     "start_time": "2023-11-04T20:11:43.138596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/gpt2-base-gedi-detoxification were not used when initializing GPT2LMHeadModel: ['logit_scale', 'bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(32100, 1024)\n    (wpe): Embedding(1024, 1024)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-23): 24 x GPT2Block(\n        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=32100, bias=False)\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gedi_dis = AutoModelForCausalLM.from_pretrained(dis_name)\n",
    "\n",
    "gedi_dis.bias = torch.tensor([[0.08441592, -0.08441573]])\n",
    "gedi_dis.logit_scale = torch.tensor([[1.2701858]])\n",
    "\n",
    "gedi_dis.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:49.977341Z",
     "start_time": "2023-11-04T20:11:44.831954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gedi_adapter = GediAdapter(\n",
    "    model=model,\n",
    "    gedi_model=gedi_dis,\n",
    "    tokenizer=tokenizer,\n",
    "    gedi_logit_coef=10,\n",
    "    target=0,\n",
    "    reg_alpha=3e-5,\n",
    "    neg_code=NEW_NEG,\n",
    "    pos_code=NEW_POS,\n",
    "    ub=0.01\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:49.978129Z",
     "start_time": "2023-11-04T20:11:49.952561Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes, with some nutcase who says he cured him.\n",
      "tensor([[    0,  2163,     6,    28,     3,     9,   720,  1033,   195,   113,\n",
      "           243,     3,    88,   141, 28648,   376,     5,     1]])\n",
      "Yes, with a bitchell who said he had healed him.\n"
     ]
    }
   ],
   "source": [
    "text = df.data['toxic'].sample(n=1).values[0]\n",
    "inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "result = gedi_adapter.generate(inputs, do_sample=False, num_return_sequences=1, temperature=0.0,\n",
    "                               repetition_penalty=3.0, num_beams=2, bad_words_ids=[[2]])\n",
    "print(text)\n",
    "print(result)\n",
    "for r in result:\n",
    "    print(tokenizer.decode(r, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:11:56.632757Z",
     "start_time": "2023-11-04T20:11:49.958978Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Trying Roberta based toxicity classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c52fb5b0dac0452cbeb1121a10064451"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8699b7c06cf549f899d617da745a6aed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/roberta_toxicity_classifier_v1 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf7e2dfbf0ae4db4a6dbabbf09130c19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e61debe4364349cbb36b6cdd70c7e8d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba0582a36ec748d3bae1088e85c243c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53fd1a05938b4c91bc459bf6e3cea6cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer\n",
    "\n",
    "clf_name = 's-nlp/roberta_toxicity_classifier_v1'\n",
    "clf = RobertaForSequenceClassification.from_pretrained(clf_name)\n",
    "clf_tokenizer = RobertaTokenizer.from_pretrained(clf_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:13:46.147066Z",
     "start_time": "2023-11-04T20:12:43.124612Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def predict_toxicity(texts):\n",
    "    with torch.inference_mode():\n",
    "        inputs = clf_tokenizer(texts, return_tensors='pt', padding=True).to(clf.device)\n",
    "        out = torch.softmax(clf(**inputs).logits, -1)[:, 1].cpu().numpy()\n",
    "    return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:13:46.154684Z",
     "start_time": "2023-11-04T20:13:46.150971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6.9651840e-05, 9.8459953e-01], dtype=float32)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_toxicity(['You are a good person', 'You are a bad person'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T20:15:13.951563Z",
     "start_time": "2023-11-04T20:15:13.915939Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, classifier works well."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
