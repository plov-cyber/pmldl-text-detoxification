{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Models Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c537721dbcd6babd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importing Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "from src.data.make_dataset import TextDataset\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from src.models.gedi_adapter import GediAdapter\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:43:14.185631Z",
     "start_time": "2023-11-02T20:43:13.091230Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Importing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pickle.load(open('../data/interim/text_dataset.pkl', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:44:37.499886Z",
     "start_time": "2023-11-02T20:44:37.312368Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                toxic  \\\n5   I'm not gonna have a child... ...with the same...   \n6   They're all laughing at us, so we'll kick your...   \n7     Maine was very short on black people back then.   \n11  So now their spirits are cursed, walking back ...   \n13               Come on, Cal, leave that shit alone.   \n\n                                               normal  toxic_reduction  \n5   I'm not going to breed kids with a genetic dis...         0.915109  \n6             they're laughing at us. We'll show you.         0.999361  \n7              there wasn't much black in Maine then.         0.814971  \n11  their souls are cursed, they guard the paths, ...         0.698517  \n13                         come on, Cal, put it down.         0.999357  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic</th>\n      <th>normal</th>\n      <th>toxic_reduction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>I'm not gonna have a child... ...with the same...</td>\n      <td>I'm not going to breed kids with a genetic dis...</td>\n      <td>0.915109</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>They're all laughing at us, so we'll kick your...</td>\n      <td>they're laughing at us. We'll show you.</td>\n      <td>0.999361</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Maine was very short on black people back then.</td>\n      <td>there wasn't much black in Maine then.</td>\n      <td>0.814971</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>So now their spirits are cursed, walking back ...</td>\n      <td>their souls are cursed, they guard the paths, ...</td>\n      <td>0.698517</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Come on, Cal, leave that shit alone.</td>\n      <td>come on, Cal, put it down.</td>\n      <td>0.999357</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:44:37.721217Z",
     "start_time": "2023-11-02T20:44:37.712562Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Splitting Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = df.split(0.7, 0.1, 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:44:40.657469Z",
     "start_time": "2023-11-02T20:44:40.550452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "((404444, 3), (57778, 3), (115555, 3))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape, val_dataset.data.shape, test_dataset.data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:44:40.745714Z",
     "start_time": "2023-11-02T20:44:40.739634Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Trying GPT-2 based model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tokenizer_name = \"s-nlp/t5-paraphrase-paws-msrp-opinosis-paranmt\"\n",
    "model_name = tokenizer_name\n",
    "dis_name = 's-nlp/gpt2-base-gedi-detoxification'\n",
    "\n",
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:47:22.284579Z",
     "start_time": "2023-11-02T20:47:22.281972Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "NEW_POS = tokenizer.encode('normal', add_special_tokens=False)[0]\n",
    "NEW_NEG = tokenizer.encode('toxic', add_special_tokens=False)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:47:24.050266Z",
     "start_time": "2023-11-02T20:47:22.911501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(32100, 768)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:47:26.104932Z",
     "start_time": "2023-11-02T20:47:24.050885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at s-nlp/gpt2-base-gedi-detoxification were not used when initializing GPT2LMHeadModel: ['logit_scale', 'bias']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(32100, 1024)\n    (wpe): Embedding(1024, 1024)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-23): 24 x GPT2Block(\n        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=1024, out_features=32100, bias=False)\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gedi_dis = AutoModelForCausalLM.from_pretrained(dis_name)\n",
    "\n",
    "gedi_dis.bias = torch.tensor([[0.08441592, -0.08441573]])\n",
    "gedi_dis.logit_scale = torch.tensor([[1.2701858]])\n",
    "\n",
    "gedi_dis.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:48:26.700503Z",
     "start_time": "2023-11-02T20:48:21.006562Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "gedi_adapter = GediAdapter(\n",
    "    model=model,\n",
    "    gedi_model=gedi_dis,\n",
    "    tokenizer=tokenizer,\n",
    "    gedi_logit_coef=10,\n",
    "    target=0,\n",
    "    reg_alpha=3e-5,\n",
    "    neg_code=NEW_NEG,\n",
    "    pos_code=NEW_POS,\n",
    "    ub=0.01\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:48:26.757537Z",
     "start_time": "2023-11-02T20:48:26.690379Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go gank ourselves a paris hilton.\n",
      "tensor([[   0,  752,   31,    7,  281,   12, 1919,    5,    1]])\n",
      "let's go to Paris.\n"
     ]
    }
   ],
   "source": [
    "text = df.data['toxic'].sample(n=1).values[0]\n",
    "inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "result = gedi_adapter.generate(inputs, do_sample=False, num_return_sequences=1, temperature=0.0,\n",
    "                               repetition_penalty=3.0, num_beams=2, bad_words_ids=[[2]])\n",
    "print(text)\n",
    "print(result)\n",
    "for r in result:\n",
    "    print(tokenizer.decode(r, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T20:50:29.638014Z",
     "start_time": "2023-11-02T20:50:26.034132Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
